{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import io, os\n",
    "import functools\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Lambda, SpatialDropout2D, ELU\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import Cropping2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "try_prefix = 'try'\n",
    "log_file = 'driving_log.csv'\n",
    "img_dir = 'IMG'\n",
    "train_file = os.path.join(data_dir, 'train.csv')\n",
    "validation_file = os.path.join(data_dir, 'validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tryouts(data_dir, prefix):\n",
    "    filenames = os.listdir(data_dir)\n",
    "    return sorted(list(map(lambda d: os.path.join(data_dir, d), filter(lambda s: s.startswith(prefix), filenames))))\n",
    "\n",
    "def fix_logs_paths(img_dir, data_frame):\n",
    "    pathfn = lambda p: os.path.join(img_dir, p.split('/')[-1])\n",
    "    data_frame.center = data_frame.center.apply(pathfn)\n",
    "    data_frame.left = data_frame.left.apply(pathfn)\n",
    "    data_frame.right = data_frame.right.apply(pathfn)\n",
    "    \n",
    "def load_log(log_dir, log_file, img_dir):\n",
    "    f = os.path.join(log_dir, log_file)\n",
    "    df = pd.read_csv(f, header=None, names=['center','left','right', 'angle', 'throttle', 'break', 'speed'])\n",
    "    i = os.path.join(log_dir, img_dir)\n",
    "    fix_logs_paths(i, df)\n",
    "    return df\n",
    "        \n",
    "def merge_logs(dfs):\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "def prepare_log():\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    tryouts = find_tryouts(data_dir, try_prefix)\n",
    "    log_frames = list(map(lambda t: load_log(t, log_file, img_dir), tryouts))\n",
    "    merged_log = merge_logs(log_frames)\n",
    "    train_samples, validation_samples = train_test_split(merged_log, test_size=0.2)\n",
    "    train_samples = train_samples.reindex(np.random.permutation(train_samples.index))\n",
    "    validation_samples = validation_samples.reindex(np.random.permutation(validation_samples.index))\n",
    "    train_samples.to_csv(train_file)\n",
    "    validation_samples.to_csv(validation_file)\n",
    "    return len(train_samples), len(validation_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(file_name, batch_size):\n",
    "    from sklearn.utils import shuffle\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        chunk_iter = pd.read_csv(file_name, chunksize=batch_size)\n",
    "        for chunk in chunk_iter:\n",
    "            images = []\n",
    "            angles = []\n",
    "            for row in chunk.itertuples():\n",
    "                img = cv2.imread(row.center)\n",
    "                ang = float(row.angle)\n",
    "                images.append(img)\n",
    "                angles.append(ang)\n",
    "            \n",
    "            # trim image to only see section with road\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCH = 32\n",
    "\n",
    "train_size, validation_size = prepare_log()\n",
    "\n",
    "train_generator = generator(train_file, BATCH_SIZE)\n",
    "validation_generator = generator(validation_file, BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_cropped(img):\n",
    "    import tensorflow as tf  # This import is required here otherwise the model cannot be loaded in drive.py\n",
    "    return tf.image.resize_images(img, (40, 160))\n",
    "\n",
    "def resize_img(img):\n",
    "    import tensorflow as tf  # This import is required here otherwise the model cannot be loaded in drive.py\n",
    "    return tf.image.resize_images(img, (64, 128))\n",
    "\n",
    "def create_model1():\n",
    "    model = Sequential([\n",
    "        Lambda(lambda x: x/127.5 - 1., input_shape=(160, 320, 3)),\n",
    "        Lambda(resize_img),\n",
    "        Convolution2D(16, (5, 5), activation='relu', padding=\"same\"),\n",
    "        MaxPooling2D((2,2)),\n",
    "        Convolution2D(32, (5, 5), activation='relu', padding=\"same\"),\n",
    "        MaxPooling2D((2,2)),\n",
    "        Dropout(0.5),\n",
    "        Flatten(),\n",
    "        Dense(100, activation='relu'),\n",
    "        Dense(50, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\", metrics=['accuracy'])   \n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def create_model2():\n",
    "    model = Sequential([\n",
    "        Lambda(lambda x: x/127.5 - 1., input_shape=(160, 320, 3), output_shape=(160, 320, 3)),\n",
    "        Lambda(resize_img),\n",
    "        Convolution2D(16, (8, 8), strides=(4, 4), padding=\"same\"),\n",
    "        ELU(),\n",
    "        Convolution2D(32, (5, 5), strides=(2, 2), padding=\"same\"),\n",
    "        ELU(),\n",
    "        Convolution2D(64, (5, 5), strides=(2, 2), padding=\"same\"),\n",
    "        Flatten(),\n",
    "        Dropout(.5),\n",
    "        ELU(),\n",
    "        Dense(512),\n",
    "        Dropout(.7),\n",
    "        ELU(),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\", metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def create_model3():\n",
    "    model = Sequential([\n",
    "        # Crop 70 pixels from the top of the image and 25 from the bottom\n",
    "        Cropping2D(cropping=((70, 20), (0, 0)), input_shape=(160, 320, 3)),\n",
    "        # Resize the data for drive.py\n",
    "        Lambda(resize_cropped),\n",
    "        # Normalize images\n",
    "        Lambda(lambda x: (x/255.0)-0.5),\n",
    "        # Conv layer 1\n",
    "        Convolution2D(16, (8, 8), strides=(4, 4), padding=\"same\", activation='elu'),\n",
    "        # Conv layer 2\n",
    "        Convolution2D(32, (5, 5), strides=(2, 2), padding=\"same\", activation='elu'),\n",
    "        # Conv layer 3\n",
    "        Convolution2D(64, (5, 5), strides=(2, 2), padding=\"same\", activation='elu'),\n",
    "\n",
    "        Flatten(),\n",
    "        Dropout(.5),\n",
    "        ELU(),\n",
    "\n",
    "        Dense(512, activation='elu'),\n",
    "        Dropout(.7),\n",
    "\n",
    "        Dense(50, activation='elu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def save_model(model, filename):\n",
    "    model.save(filename)\n",
    "    print(\"model saved, filename: {}.\".format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_46 (Lambda)           (None, 160, 320, 3)       0         \n",
      "_________________________________________________________________\n",
      "lambda_47 (Lambda)           (None, 16, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_68 (Conv2D)           (None, 4, 8, 16)          3088      \n",
      "_________________________________________________________________\n",
      "elu_46 (ELU)                 (None, 4, 8, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_69 (Conv2D)           (None, 2, 4, 32)          12832     \n",
      "_________________________________________________________________\n",
      "elu_47 (ELU)                 (None, 2, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_70 (Conv2D)           (None, 1, 2, 64)          51264     \n",
      "_________________________________________________________________\n",
      "flatten_25 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "elu_48 (ELU)                 (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "elu_49 (ELU)                 (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 133,745\n",
      "Trainable params: 133,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "169/168 [==============================] - 55s 327ms/step - loss: 0.0387 - acc: 0.6817 - val_loss: 0.0309 - val_acc: 0.6814\n",
      "Epoch 2/32\n",
      "168/168 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.6818"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-bdae96c58443>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mm_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"model{}.h5\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-78-bdae96c58443>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(model, filename)\u001b[0m\n\u001b[1;32m      5\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_size\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                         epochs=EPOCH)\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1154\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2097\u001b[0m                                 \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2098\u001b[0m                                 \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                                 use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m   2100\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2101\u001b[0m                             \u001b[0;31m# No need for try/except because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2194\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2195\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2196\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2197\u001b[0m                     raise ValueError('Output of generator should be a tuple '\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    659\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def run_model(model, filename):\n",
    "    model.fit_generator(train_generator, \n",
    "                        steps_per_epoch=train_size/BATCH_SIZE, \n",
    "                        validation_data=validation_generator, \n",
    "                        validation_steps=validation_size/BATCH_SIZE, \n",
    "                        epochs=EPOCH)\n",
    "    save_model(model, filename)  \n",
    "   \n",
    "\n",
    "models = [create_model1() ,create_model2(), create_model3()] \n",
    "for i, m in enumerate(models):\n",
    "    m_name = \"model{}.h5\".format(i)\n",
    "    run_model(m, m_name) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
